# Churn Prediction Pipeline - Vertex AI

Este proyecto implementa un **pipeline de Machine Learning E2E** en **Vertex AI Pipelines** para predecir la fuga de clientes (*churn prediction*).

El flujo general incluye:
1. **Ingesta de datos** (CSV desde GCS ‚Üí Parquet).
2. **Feature Engineering** (creaci√≥n de variables derivadas).
3. **Preprocesamiento** (limpieza, escalado, codificaci√≥n).
4. **Entrenamiento y validaci√≥n** (XGBoost con m√©trica ROC-AUC).
5. **Registro condicional** en **Model Registry**.

---

## üìå Diagrama del Pipeline

![Vertex AI Pipeline Diagram](data/docs/img/churn_pipeline_diagram.png)


---

## 1Ô∏è‚É£ Clonar el repositorio en una VM de Vertex AI Workbench

```bash
git clone https://github.com/MMejiaCabello/Miguel_Mejia_Assessment_MLE.git
cd 01_pipeline_ml
```

## 2Ô∏è‚É£ Gesti√≥n de Entornos Virtuales con Conda y Poetry
    
### Creaci√≥n de un Entorno con Conda
    
```sh
conda create -n mle_pipeline_env python=3.10
conda activate mle_pipeline_env
```

### Instalaci√≥n de Poetry en el Entorno de Conda

```sh
conda install -c conda-forge poetry

```

### Configuraci√≥n de la Estructura del Proyecto con Poetry

```sh
PROJECT_NAME=01_pipeline_ml
poetry new ${PROJECT_NAME}

cd ${PROJECT_NAME}
```

### Adici√≥n de Dependencias

```sh
poetry add kfp google-cloud-aiplatform google-cloud-storage
```

## 3Ô∏è‚É£ Variables importantes

En `churn_pipeline.py`, valida las siguientes variables:

```sh
csv_path = "gs://assessment-mle/datasets/clientes.csv"
project_id = "<TU_PROJECT_ID>"
region = "us-central1"
model_display_name = "churn-xgb"
auc_threshold = 0.70
```

- csv_path: Ruta del CSV en GCS.
- project_id: Proyecto de GCP.
- region: Regi√≥n de Vertex AI.
- model_display_name: Nombre con el que se registrar√° el modelo.
- auc_threshold: Umbral m√≠nimo de ROC-AUC para registrar el modelo.


## 4Ô∏è‚É£ Compilar el pipeline

Genera el archivo .yaml del pipeline para Vertex AI:

```sh
poetry run python compile_pipeline.py
```
Esto generar√° churn_pipeline.yaml en la ra√≠z del proyecto.

## 5Ô∏è‚É£ Ejecutar el pipeline en Vertex AI


```sh
poetry run python run_pipeline.py
```
Este script:

- Sube el .yaml a Vertex AI Pipelines.
- Ejecuta el pipeline con par√°metros configurados.
- Permite monitorear la ejecuci√≥n desde la consola de Vertex AI

## 6Ô∏è‚É£ Componentes del Pipeline

| Componente                  | Descripci√≥n                                                                                                    |
| --------------------------- | -------------------------------------------------------------------------------------------------------------- |
| **load_data.py**            | Carga el CSV desde GCS, lo convierte a Parquet y lo guarda como artifact `Dataset`.                            |
| **feature_engineering.py**  | Crea variables derivadas como `d√≠as desde √∫ltima compra`, `antig√ºedad del cliente` y variables de interacci√≥n. |
| **preprocess.py**           | Limpieza, codificaci√≥n y escalado de datos para entrenamiento.                                                 |
| **train_model.py**          | Entrena un modelo XGBoost, calcula m√©tricas y guarda el modelo en formato `.bst` (compatible con Vertex AI).   |
| **register_model.py**       | Registra el modelo en **Model Registry** si el AUC ‚â• `auc_threshold`.                                          |


## 7Ô∏è‚É£ Estructura del Proyecto

La estructura del proyecto es la siguiente:

```bash
01_pipeline_ml/
‚îú‚îÄ‚îÄ compile_pipeline.py        # Compila el pipeline a YAML
‚îú‚îÄ‚îÄ run_pipeline.py            # Ejecuta el pipeline en Vertex AI
‚îú‚îÄ‚îÄ pipelines/
‚îÇ   ‚îî‚îÄ‚îÄ churn_pipeline.py      # Definici√≥n del pipeline E2E
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ ingestion/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ load_data.py
‚îÇ   ‚îú‚îÄ‚îÄ features/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ feature_engineering.py
‚îÇ   ‚îú‚îÄ‚îÄ preprocessing/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ preprocess.py
‚îÇ   ‚îú‚îÄ‚îÄ training/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ train_model.py
‚îÇ   ‚îî‚îÄ‚îÄ deployment/
‚îÇ       ‚îî‚îÄ‚îÄ register_model.py
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ clientes.csv            # Dataset con informaci√≥n de clientes
‚îú‚îÄ‚îÄ pyproject.toml              # Configuraci√≥n de Poetry
‚îî‚îÄ‚îÄ README.md
```

## 8Ô∏è‚É£ Registro de Modelo

El registro en `Model Registry` es condicional:
- ‚úÖ Si ROC-AUC >= auc_threshold ‚Üí se registra el modelo.
- ‚ùå Si no ‚Üí se detiene la ejecuci√≥n y se deja traza del motivo.

Para forzar registro:
- Cambia auc_threshold = 0.0 temporalmente.

üí° **Nota**: Antes de ejecutar el pipeline en Vertex AI, aseg√∫rate de:
1. Tener habilitadas las APIs necesarias en GCP (`Vertex AI API`, `Artifact Registry API`, `Cloud Storage API`).
2. Contar con permisos adecuados (`roles/aiplatform.admin`, `roles/storage.admin`).
3. Haber configurado el entorno virtual con Poetry y todas las dependencias instaladas.

---